# Project Rubric 

## Documentation
| Success Criteria |	Specifications  |  
|--------|--------|
| Explain the pipeline architecture. | The `README` contains an explanation of:  <ul><li> The pipeline architecture, including data, hyperparameter tuning, and classification algorithm. <li> The benefits of the chosen parameter sampler. <li> The benefits of the chosen early stopping policy. </li></ul> |   
| Compare a provided model with one generated by `Azure AutoML`. | The `README` contains: <ul><li> One or more sentences describing the model and parameters generated by `Azure AutoML`. <li> Two or more sentences comparing the 2 models and their performance. </li></ul> |
| Explain and justify ways to improve models. | The `README` contains two or more sentences explaining potential improvements for a future experiment and why these improvements might improve the model. |

## Training Pipeline and `AutoML`
| Success Criteria |	Specifications  |  
|--------|--------|
| Pass parameters to training scripts. | All specifiable parameters of the training script are specified in the `Hyperdrive` config. |
|  Use `HyperDrive ` to automatically find optimal parameters. | A `Hyperdrive` config is used and includes: <ul><li> A parameter sampler <li> A policy for early stopping </li></ul>|
| Retrieve the best run using `.get_best_run_by_primary_metric()`. | `.get_best_run_by_primary_metric()` is used on the `Hyperdrive` run to retrieve the best run. | 
| Use the `RunDetails` widget to explore run metrics. | The `Hyperdrive` run is passed to the `RunDetails` widget. | 
| Create an `AutoMLConfig` for training. | The solution notebook includes an `AutoML` config, which contains the following parameters: <ul><li> task <li> primary_metric <li> experiment_timeout_minutes <li> training_data <li> label_column_name <li> n_cross_validations </li></ul> |

## Infrastructure
| Success Criteria |	Specifications  |  
|--------|--------|
|Create a compute cluster using the SDK. | A compute cluster is created using the `Azure SDK` and the `ComputeTarget` and `AmlCompute` objects. |
| Import data to a Dataset using the SDK.| A `TabularDatasetFactory` is used to create a dataset from the provided link.| 
| Clean up deployed resources. | The delete method of the `AmlCompute` object is used to remove the cluster following training, **OR**, An image of the compute cluster being selected for deletion is included in the `README`.|

